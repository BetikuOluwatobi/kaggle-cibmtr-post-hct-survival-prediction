{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6428a92",
   "metadata": {
    "papermill": {
     "duration": 0.003938,
     "end_time": "2025-02-25T17:56:17.231861",
     "exception": false,
     "start_time": "2025-02-25T17:56:17.227923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install lifelines package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aba6785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:56:17.240824Z",
     "iopub.status.busy": "2025-02-25T17:56:17.240443Z",
     "iopub.status.idle": "2025-02-25T17:56:44.364636Z",
     "shell.execute_reply": "2025-02-25T17:56:44.363344Z"
    },
    "papermill": {
     "duration": 27.132258,
     "end_time": "2025-02-25T17:56:44.367859",
     "exception": false,
     "start_time": "2025-02-25T17:56:17.235601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/cibmtr_lifelines/autograd-1.7.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd==1.7.0) (1.26.4)\r\n",
      "autograd is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Processing /kaggle/input/cibmtr_lifelines/autograd-gamma-0.5.0.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: autograd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.7.0)\r\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.13.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd>=1.2.0->autograd-gamma==0.5.0) (1.26.4)\r\n",
      "Building wheels for collected packages: autograd-gamma\r\n",
      "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=2e01f7c4867887732d2041fda002b04d07824652bdcf47e69bf0f5ce821940e3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/97/c4/e9/b8d72881091567d3cfbb1734056aa8ad5731785576546d141c\r\n",
      "Successfully built autograd-gamma\r\n",
      "Installing collected packages: autograd-gamma\r\n",
      "Successfully installed autograd-gamma-0.5.0\r\n",
      "Processing /kaggle/input/cibmtr_lifelines/interface_meta-1.3.0-py3-none-any.whl\r\n",
      "Installing collected packages: interface-meta\r\n",
      "Successfully installed interface-meta-1.3.0\r\n",
      "Processing /kaggle/input/cibmtr_lifelines/formulaic-1.1.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.1.1) (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.1.1) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.1.1) (2.1.4)\r\n",
      "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.1.1) (1.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.1.1) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.1.1) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.1.1) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.1.1) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.1.1) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->formulaic==1.1.1) (1.16.0)\r\n",
      "Installing collected packages: formulaic\r\n",
      "Successfully installed formulaic-1.1.1\r\n",
      "Processing /kaggle/input/cibmtr_lifelines/lifelines-0.30.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.13.1)\r\n",
      "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (2.1.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (3.7.1)\r\n",
      "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.7.0)\r\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (0.5.0)\r\n",
      "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.1.1)\r\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.16.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.3.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (4.53.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (24.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (10.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (3.1.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines==0.30.0) (1.16.0)\r\n",
      "Installing collected packages: lifelines\r\n",
      "Successfully installed lifelines-0.30.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/cibmtr_lifelines/autograd-1.7.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/cibmtr_lifelines/autograd-gamma-0.5.0.tar.gz\n",
    "!pip install /kaggle/input/cibmtr_lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/cibmtr_lifelines/formulaic-1.1.1-py3-none-any.whl\n",
    "!pip install /kaggle/input/cibmtr_lifelines/lifelines-0.30.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fd753d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-25T17:56:44.379844Z",
     "iopub.status.busy": "2025-02-25T17:56:44.379413Z",
     "iopub.status.idle": "2025-02-25T17:56:57.335155Z",
     "shell.execute_reply": "2025-02-25T17:56:57.333925Z"
    },
    "papermill": {
     "duration": 12.963871,
     "end_time": "2025-02-25T17:56:57.337282",
     "exception": false,
     "start_time": "2025-02-25T17:56:44.373411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\n",
      "/kaggle/input/equity-post-HCT-survival-predictions/data_dictionary.csv\n",
      "/kaggle/input/equity-post-HCT-survival-predictions/train.csv\n",
      "/kaggle/input/equity-post-HCT-survival-predictions/test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch, math, time\n",
    "import polars as pl\n",
    "import glob, pathlib, json, warnings, lifelines\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "import missingno as msno\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, ClassifierMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearnex import patch_sklearn\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter, NelsonAalenFitter, WeibullFitter,ExponentialFitter, LogNormalFitter, NelsonAalenFitter\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import logging, os, tqdm\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from metric import score as score_f\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/equity-post-HCT-survival-predictions'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('sklearnex').setLevel(logging.WARNING)\n",
    "patch_sklearn(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14adb17c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:56:57.349299Z",
     "iopub.status.busy": "2025-02-25T17:56:57.348555Z",
     "iopub.status.idle": "2025-02-25T17:56:57.870362Z",
     "shell.execute_reply": "2025-02-25T17:56:57.869131Z"
    },
    "papermill": {
     "duration": 0.530041,
     "end_time": "2025-02-25T17:56:57.872374",
     "exception": false,
     "start_time": "2025-02-25T17:56:57.342333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dic = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/data_dictionary.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
    "train = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a328cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:56:57.884870Z",
     "iopub.status.busy": "2025-02-25T17:56:57.884293Z",
     "iopub.status.idle": "2025-02-25T17:56:57.905488Z",
     "shell.execute_reply": "2025-02-25T17:56:57.903926Z"
    },
    "papermill": {
     "duration": 0.030232,
     "end_time": "2025-02-25T17:56:57.907639",
     "exception": false,
     "start_time": "2025-02-25T17:56:57.877407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_types = {var:typ for idx, (var, _, typ, _) in data_dic.iterrows()}\n",
    "categorical_columns = [key for key, value in feature_types.items() if value==\"Categorical\" and key!=\"efs\"]\n",
    "numerical_columns = [key for key, value in feature_types.items() if value==\"Numerical\" and key!=\"efs_time\"]\n",
    "seed = 11\n",
    "\n",
    "with open(\"/kaggle/input/cibmtr/features_information_naf_v1.json\", mode=\"r\") as file:\n",
    "    best_scores = json.load(file)\n",
    "\n",
    "with open(\"/kaggle/input/cibmtr/features_information_naf.json\", mode=\"r\") as file:\n",
    "    best_scores_naf = json.load(file)\n",
    "    \n",
    "top_k_comb_naf = sorted(best_scores_naf.items(), key=lambda x: (x[-1], x[0]), reverse=True)[:10] #best feature combination\n",
    "top_k_comb = sorted(best_scores.items(), key=lambda x: (x[-1], x[0]), reverse=True)[:5] #best feature combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd79691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:56:57.919207Z",
     "iopub.status.busy": "2025-02-25T17:56:57.918693Z",
     "iopub.status.idle": "2025-02-25T17:56:57.951075Z",
     "shell.execute_reply": "2025-02-25T17:56:57.949736Z"
    },
    "papermill": {
     "duration": 0.040747,
     "end_time": "2025-02-25T17:56:57.953354",
     "exception": false,
     "start_time": "2025-02-25T17:56:57.912607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NANCategorical(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, key=\"UNK\"):\n",
    "        super().__init__()\n",
    "        self.columns = columns\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.columns] = X[self.columns].fillna(self.key)\n",
    "        return X\n",
    "\n",
    "class NANNumerical(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, key=-1):\n",
    "        super().__init__()\n",
    "        self.columns = columns\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X[self.columns] = X[self.columns].fillna(self.key)\n",
    "        return X\n",
    "\n",
    "class NUMScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, scaler=StandardScaler()):\n",
    "        super().__init__()\n",
    "        self.columns = columns\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[self.columns])\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X[self.columns] = self.scaler.transform(X[self.columns])\n",
    "        return X\n",
    "\n",
    "def make_score(X, predictions):\n",
    "    y_true = X[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "    y_pred = X[[\"ID\"]].copy()\n",
    "    y_pred[\"prediction\"] = predictions\n",
    "    m = score_f(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "    return m\n",
    "\n",
    "class FeatureEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, encoder=LabelEncoder()):\n",
    "        self.columns = columns\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        for col in self.columns:\n",
    "            X_transformed[col] = self.encoder.fit_transform(X[col])\n",
    "        return X_transformed\n",
    "\n",
    "class SurvivalEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, survival_function, name):\n",
    "        self.params = {'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'model__force_col_wise': True, 'learning_rate': 0.65, \n",
    "                       'max_depth': 3, 'metric': 'rmse', 'min_child_samples': 64, 'min_split_gain': 0.03, 'n_estimators': 300, \n",
    "                       'num_leaves': 4, 'verbose': -1}\n",
    "        self.model = make_lgb(params=self.params,seeds=[234, 262, 342, 408])\n",
    "        self.columns = columns\n",
    "        self.name = name\n",
    "        self.survival_function = survival_function\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        y_kmf = self.survival_function(X, time_col='efs_time', event_col='efs')\n",
    "        self.model.fit(X[self.columns], y_kmf)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(self.model.predict(X[self.columns]), columns=[self.name], index=X.index)\n",
    "\n",
    "class ClassEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, label, name):\n",
    "        self.params = {'boosting_type': 'gbdt', 'colsample_bytree': 0.75, 'model__force_col_wise': True, 'learning_rate': 0.65, \n",
    "                       'max_depth': 3, 'metric': 'rmse', 'min_child_samples': 64, 'min_split_gain': 0.03, 'n_estimators': 300, \n",
    "                       'num_leaves': 4, 'verbose': -1}\n",
    "        self.model = make_lgb(params=self.params,seeds=[234, 262, 342, 408])\n",
    "        self.columns = columns\n",
    "        self.name = name\n",
    "        self.label = label\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.model.fit(X[self.columns], X[self.label])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(self.model.predict(X[self.columns]), columns=[self.name], index=X.index)\n",
    "\n",
    "class AddSurvivalEstimates(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, survival_functions, compute_aggregates):\n",
    "        self.survival_functions = survival_functions\n",
    "        self.transformers = {}\n",
    "        self.compute_aggregates = compute_aggregates\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.survival_functions:\n",
    "            for name, func in self.survival_functions.items():#list(X.columns[1:-2]) top_k_comb_naf[1][0].split(\"/\")\n",
    "                if func == \"efs\" or func == \"efs_time\":\n",
    "                    estimator = ClassEstimator(columns=list(X.columns[1:-2]), label=func, name=name)\n",
    "                    estimator.fit(X)\n",
    "                    self.transformers[name] = estimator\n",
    "                else:\n",
    "                    estimator = SurvivalEstimator(survival_function=func, columns=list(X.columns[1:-2]), name=name)\n",
    "                    estimator.fit(X)\n",
    "                    self.transformers[name] = estimator\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        if self.transformers:\n",
    "            X_transforms = [X] + [transformer.transform(X) for _, transformer in self.transformers.items()] + [self.compute_aggregates(X)]\n",
    "            X_transformed = pd.concat(X_transforms, axis=1)\n",
    "            return X_transformed\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "class SELColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        super().__init__()\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.columns]\n",
    "\n",
    "def make_pipeline(columns, model, categorical_columns, numerical_columns, compute_aggregates, \n",
    "                  survival_functions, plain=False):\n",
    "    if plain:\n",
    "        pipe = Pipeline(\n",
    "            steps=[\n",
    "                ('nancategorical', NANCategorical(columns=categorical_columns, key=\"UNK\")), \n",
    "                ('nannumerical', NANNumerical(columns=numerical_columns, key=-1)),\n",
    "                ('labelencoder', FeatureEncoder(columns=categorical_columns, encoder=LabelEncoder())\n",
    "                ),\n",
    "                ('numscaler', NUMScaler(columns=numerical_columns, \n",
    "                                        scaler=MinMaxScaler(feature_range=(0, 1),clip=False))\n",
    "                ),\n",
    "                ('survivalestimates', AddSurvivalEstimates(survival_functions=survival_functions, compute_aggregates=compute_aggregates))\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        pipe = Pipeline(\n",
    "            steps=[\n",
    "                ('nancategorical', NANCategorical(columns=categorical_columns, key=\"UNK\")), \n",
    "                ('nannumerical', NANNumerical(columns=numerical_columns, key=-1)),\n",
    "                ('labelencoder', FeatureEncoder(columns=categorical_columns, encoder=LabelEncoder())),\n",
    "                ('numscaler', NUMScaler(columns=numerical_columns, \n",
    "                                        scaler=MinMaxScaler(feature_range=(0, 1),clip=False))\n",
    "                ),\n",
    "                ('survivalestimates', AddSurvivalEstimates(survival_functions=survival_functions, compute_aggregates=compute_aggregates)),\n",
    "                ('selcolumns', SELColumns(columns=columns)),\n",
    "                (\"model\", model)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return pipe\n",
    "    \n",
    "def transform_survival_probability(df, time_col='efs_time', event_col='efs'):\n",
    "    \"\"\"\n",
    "    Transform using survival probability estimates\n",
    "    \"\"\"\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(durations=np.log(df[time_col].values), event_observed=df[event_col])\n",
    "    y = kmf.survival_function_at_times(np.log(df[time_col].values)).values\n",
    "    return y\n",
    "\n",
    "def transform_survival_nelson(df, time_col='efs_time', event_col='efs'):\n",
    "    \"\"\"\n",
    "    Transform using survival probability estimates\n",
    "    \"\"\"\n",
    "    naf = NelsonAalenFitter()\n",
    "    naf.fit(durations=np.log(df[time_col].values), event_observed=df[event_col])\n",
    "    y = -naf.cumulative_hazard_at_times(np.log(df[time_col].values)).values\n",
    "    return y\n",
    "    \n",
    "def make_lgb(params,seeds):\n",
    "    clfs = []\n",
    "    for i, seed in enumerate(seeds):\n",
    "        params[\"random_state\"] = seed\n",
    "        clfs.append((f\"lgb_{i+1}\", lgb.LGBMRegressor(**params)))\n",
    "    \n",
    "    return VotingRegressor(clfs, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e474920",
   "metadata": {
    "papermill": {
     "duration": 0.004909,
     "end_time": "2025-02-25T17:56:57.963979",
     "exception": false,
     "start_time": "2025-02-25T17:56:57.959070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b908589d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:56:57.977337Z",
     "iopub.status.busy": "2025-02-25T17:56:57.976716Z",
     "iopub.status.idle": "2025-02-25T17:56:57.985046Z",
     "shell.execute_reply": "2025-02-25T17:56:57.983113Z"
    },
    "papermill": {
     "duration": 0.017197,
     "end_time": "2025-02-25T17:56:57.987379",
     "exception": false,
     "start_time": "2025-02-25T17:56:57.970182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_kfold(X, y, test, pipeline, n_splits=5, seed=11, shuffle=True):\n",
    "    kfold = KFold(n_splits=n_splits, random_state=seed, shuffle=shuffle)\n",
    "    predictions = np.zeros(len(test))\n",
    "    #Define cross validation\n",
    "    for i, (train_ind, test_ind) in tqdm.tqdm(enumerate(kfold.split(X)), desc=\"Evaluating Model\"):\n",
    "        #Split train data for cross validation\n",
    "        X_train, y_train = X.iloc[train_ind], y[train_ind]\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        #Generate predictions \n",
    "        predictions += pipeline.predict(test)\n",
    "    \n",
    "    return predictions/n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdc3fd29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:56:58.001145Z",
     "iopub.status.busy": "2025-02-25T17:56:58.000297Z",
     "iopub.status.idle": "2025-02-25T17:56:58.013140Z",
     "shell.execute_reply": "2025-02-25T17:56:58.011119Z"
    },
    "papermill": {
     "duration": 0.02245,
     "end_time": "2025-02-25T17:56:58.015671",
     "exception": false,
     "start_time": "2025-02-25T17:56:57.993221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_aggregates(X):\n",
    "    df = X.copy()\n",
    "    \n",
    "    # Feature 1: HLA Matching Score (Summing all HLA match variables)\n",
    "    hla_columns = [col for col in df.columns if 'hla_match' in col]\n",
    "    df['hla_match_score_max'] = df[hla_columns].max(axis=1)\n",
    "    \n",
    "    # Feature 2: T-cell Epitope Mismatch Score (Combining `tce_match` and `tce_div_match`)\n",
    "    df['tce_mismatch_score'] = df[['tce_match', 'tce_div_match']].sum(axis=1)\n",
    "    \n",
    "    # # Feature 3: GVHD Risk Score (Summing `gvhd_proph`, `in_vivo_tcd`, and `tce_imm_match`)\n",
    "    df['gvhd_risk_score_max'] = df[['gvhd_proph', 'in_vivo_tcd', 'tce_imm_match']].max(axis=1)\n",
    "    df['gvhd_risk_score'] = df[['gvhd_proph', 'in_vivo_tcd', 'tce_imm_match']].sum(axis=1)\n",
    "\n",
    "    earliest_year = df['year_hct'].min()\n",
    "    df['years_since_first_transplant'] = df['year_hct'] - earliest_year\n",
    "    df['donor_recipient_age_gap'] = df['donor_age'] - df['age_at_hct']\n",
    "    # # Feature 4: Comorbidity Index (Summing selected comorbidity indicators)\n",
    "    comorbidity_columns = ['diabetes', 'cardiac', 'arrhythmia', 'renal_issue',\n",
    "                           'hepatic_mild', 'hepatic_severe', 'pulm_severe', 'peptic_ulcer']\n",
    "    df['comorbidity_index'] = df[comorbidity_columns].sum(axis=1)\n",
    "    df['comorbidity_index_max'] = df[comorbidity_columns].max(axis=1)\n",
    "    df['comorbidity_index_mean'] = df[comorbidity_columns].mean(axis=1)\n",
    "    \n",
    "    return df[['gvhd_risk_score_max','comorbidity_index','comorbidity_index_max','hla_match_score_max',\n",
    "               'comorbidity_index_mean','gvhd_risk_score', 'tce_mismatch_score','years_since_first_transplant',\n",
    "               'donor_recipient_age_gap']]\n",
    "    \n",
    "\n",
    "def generate_predictions(test, train, top_k_comb, categorical_columns, numerical_columns, y_func, \n",
    "                         model, compute_aggregates, survival_functions,plain=False, n_splits=5, seed=11):\n",
    "    \n",
    "    predictions = np.zeros(len(test))\n",
    "    for cols, _ in top_k_comb:\n",
    "        cols = cols.split(\"/\")\n",
    "        pipe = make_pipeline(columns=cols, model=model, categorical_columns=categorical_columns, numerical_columns=numerical_columns, \n",
    "                             compute_aggregates=compute_aggregates, survival_functions=survival_functions, plain=plain)\n",
    "        \n",
    "        predictions += predict_kfold(\n",
    "            train, y=y_func(train), test=test, pipeline=pipe, n_splits=n_splits, seed=seed, shuffle=True\n",
    "        )\n",
    "    \n",
    "    return predictions/len(top_k_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85cee2a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T17:56:58.027649Z",
     "iopub.status.busy": "2025-02-25T17:56:58.027287Z",
     "iopub.status.idle": "2025-02-25T18:01:30.909706Z",
     "shell.execute_reply": "2025-02-25T18:01:30.908172Z"
    },
    "papermill": {
     "duration": 272.890935,
     "end_time": "2025-02-25T18:01:30.912095",
     "exception": false,
     "start_time": "2025-02-25T17:56:58.021160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model: 5it [00:57, 11.49s/it]\n",
      "Evaluating Model: 5it [00:56, 11.34s/it]\n",
      "Evaluating Model: 5it [00:49,  9.99s/it]\n",
      "Evaluating Model: 5it [00:56, 11.20s/it]\n",
      "Evaluating Model: 5it [00:52, 10.49s/it]\n"
     ]
    }
   ],
   "source": [
    "survival_funcs = {\"kmf\": transform_survival_probability, \"nelson\": transform_survival_nelson, \"efs_label\": \"efs\"}\n",
    "params = {'boosting_type': 'gbdt', 'colsample_bytree': 0.9, 'force_col_wise': True, 'learning_rate': 0.15, \n",
    "          'max_depth': 3, 'metric': 'rmse', 'min_child_samples': 84, 'min_split_gain': 0.05, 'n_estimators': 150, \n",
    "          'num_leaves': 3, 'verbose': -1}\n",
    "\n",
    "oof_kmf = generate_predictions(test, train, top_k_comb, categorical_columns, numerical_columns, y_func=transform_survival_nelson, \n",
    "                               survival_functions=survival_funcs, plain=False, n_splits=5, seed=seed, \n",
    "                               compute_aggregates=compute_aggregates, model=make_lgb(params=params,seeds=[234, 262, 342, 408]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea6ac18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T18:01:30.928282Z",
     "iopub.status.busy": "2025-02-25T18:01:30.927840Z",
     "iopub.status.idle": "2025-02-25T18:01:30.945636Z",
     "shell.execute_reply": "2025-02-25T18:01:30.944239Z"
    },
    "papermill": {
     "duration": 0.028497,
     "end_time": "2025-02-25T18:01:30.947762",
     "exception": false,
     "start_time": "2025-02-25T18:01:30.919265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "sub = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\")\n",
    "sub[\"prediction\"] = oof_kmf\n",
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89dcaad",
   "metadata": {
    "papermill": {
     "duration": 0.006532,
     "end_time": "2025-02-25T18:01:30.961352",
     "exception": false,
     "start_time": "2025-02-25T18:01:30.954820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "sourceId": 70942,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 11216057,
     "datasetId": 6449801,
     "sourceId": 10852543,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 215808140,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 216123007,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 319.813511,
   "end_time": "2025-02-25T18:01:33.612821",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-25T17:56:13.799310",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
